# ğŸ§  TP3 â€” Apprentissage Auto-SupervisÃ© (SSL)
**Auteur : Wassim CHIKHI â€” M2 VMI 2025**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vvazzim/Tp-VMI-Wassim/blob/main/deep-learning/tp3-self-supervised-learning/notebooks/Self_Supervised_Learning_Demos_final.ipynb)

---

## ğŸ¯ Objectif
Comparer diffÃ©rentes **tÃ¢ches prÃ©textes** en apprentissage auto-supervisÃ© (SSL) sur les datasets **CIFAR-10** et **STL-10**, afin dâ€™Ã©valuer leur capacitÃ© Ã  apprendre des reprÃ©sentations utiles pour la classification.

---

## âš™ï¸ Configuration
- **Encodeur** : ResNet-18 (ou CNN simple)
- **Optimiseur** : Adam, *lr = 0.001*
- **Datasets** : CIFAR-10 (32Ã—32), STL-10 (96Ã—96)
- **EntraÃ®nement** : 20 epochs (prÃ©texte) + 5 epochs (linear probe)
- **Plateforme** : Google Colab (GPU T4)

---

## ğŸ§ª MÃ©thodologie
- ImplÃ©mentation de la tÃ¢che prÃ©texte **Relative Patch Location** (Doersch et al., 2015).
- Comparaison avec **Rotation Prediction**, **Inpainting**, et **SimCLR**.
- Ã‰valuation linÃ©aire (classifieur gelÃ©) sur les reprÃ©sentations apprises.

---

## ğŸ“Š RÃ©sultats (linear probe)
| TÃ¢che prÃ©texte | CIFAR-10 | STL-10 |
|----------------|-----------|---------|
| Relative Patch | **22.6â€¯%** | **14.2â€¯%** |
| Rotation | **68.5â€¯%** | **49.3â€¯%** |
| Inpainting | **74.3â€¯%** | â€” |
| SimCLR | **81.0â€¯%** | â€” |

**Analyse :**
- La tÃ¢che **Relative Patch** apprend des structures locales mais peu transfÃ©rables.  
- **Rotation** et **SimCLR** capturent de meilleures reprÃ©sentations globales.  
- **STL-10** est plus complexe â†’ les limites des approches locales sont plus visibles.

---

## ğŸ§© Conclusion
Les tÃ¢ches **globales ou contrastives** (SimCLR, Rotation) sont les plus efficaces pour le transfert.  
Relative Patch reste utile en complÃ©ment, notamment pour des approches **multi-prÃ©texte** ou **gÃ©omÃ©triques**.

**Perspectives :**
- EntraÃ®nement plus long (epochsâ€¯â†‘)  
- Fine-tuning complet  
- Architectures plus profondes

---

## ğŸ”— Liens utiles
- Notebook Colab : badge ci-dessus â˜ï¸  
- Rapport PDF : [`rapport/CHIKHI_Wassim_TP_SSL_VMI2025.pdf`](./rapport/CHIKHI_Wassim_TP_SSL_VMI2025.pdf)

---

## ğŸ“š RÃ©fÃ©rences
- [1] Doersch, M. et al. *Unsupervised visual representation learning by context prediction* (ICCVâ€¯2015).  
- [2] Gidaris, S. et al. *Unsupervised representation learning by predicting image rotations* (arXivâ€¯2018).  
- [3] Chen, T. et al. *SimCLR: A Simple Framework for Contrastive Learning* (arXivâ€¯2020).  
- [4] Pathak, D. et al. *Context Encoders: Feature Learning by Inpainting* (CVPRâ€¯2016).  
